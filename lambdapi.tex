
LambdaPi is an implementation of the lambda-pi calculus modulo ($\lp$), so we
will first quickly describe this system, then describe the Martin-Löf Type
Theory (MLTT) we implemented, along with some property, and finally we describe
how it is embedded into LambdaPi.

\subsection{Lambda-Pi Calculus Modulo}

The lambda-pi calculus modulo is an extension on the lambda-pi calculus, so
first let's describe it. The terms are the usual terms of the $\lambda$-calculus with
dependent types~:

\[\begin{array}{rcl}
    t, u, v, T, U\dots & := & \lambda(x : T), t \\
    & | & x \\
    & | & \Pi(x : T), U \\
    & | & u\ v \\
    & | & \text{TYPE} \\
 \end{array}\]

The typing rule for abstractions is the following~:

\begin{center}\begin{prooftree}
    \hypo{\Gamma\vdash U : \text{TYPE}}
    \hypo{\Gamma, x: U\vdash t : T}
    \infer2{\Gamma\vdash \lambda(x :  U), t : \Pi(x : U), T}
\end{prooftree}\end{center}

The other typing rules are without surprise. Let's just focus on one perhaps
surprising aspect of the abstraction rule. The type of the argument must be of
type $\text{TYPE}$. But since $\Gamma\vdash\text{TYPE} : \text{TYPE}$ does not hold, as it
would make the system inconsistent, it is impossible to quantify over all types.
This is a limitation that other type systems try to avoid using hierarchies of
universes, but it make the system more complicated. While it seems a bit too
constraining not to have polymorphism, we will see in section \ref{codes} how we
can still simulate polymorphism using the modulo part of the type theory.

Now let's focus on another rule, that is standard in type theory, the conversion
rule~:

\begin{center}\begin{prooftree}
    \hypo{\Gamma\vdash t : T}
    \hypo{\Gamma\vdash T \equiv U}
    \infer2{\Gamma\vdash t : U}
\end{prooftree}\end{center}

Here $\Gamma\vdash T \equiv U$ means that $T$ and $U$ are convertible, in the case of LambdaPi
$\alpha\beta$-convertible. This is pretty standard stuff, but that's where the
\emph{modulo} part of lambda-pi calculus modulo comes in. Indeed, this systems
allows the context to extend the congruence used in the conversion rule, ie $\Gamma$
can contain new equalities that are used when applying the congruence rule. One
problem is that just doing it naively can make the type checking undecidable,
and even make the logic inconsistant. However, there is one specific case that
is both decidable and proved consistant~: when $\equiv$ is the symmetric, reflexive
and transitive closure of a strongly-normalizing confluent system $\hookrightarrow$.

This is what the current implementation of LambdaPi does~: it provides a syntax
to declare new symbols and reduction rules about those symbols, and then provide
a type-checking algorithm that works modulo the congruence generated by the
reduction rules. However, it is not able to check the confluence nor
normalisation of the system, so the proof obligation of those lies to the user.

\subsubsection{Very simple sum type}

As an example, assume we have $T$ and $U$ two types in our context, and we want
to create the type $T + U$ in LambdaPi. We would need so create a type $S$ that
would be isomorphic to the sum, then declare symbols for the constructors and
the elimination. Of course, since we cannot quantify over types, the elimination
needs to be into a specific type, let's say $C$.  Finally, we would need to add
computation rules so that the elimination of the constructors behave as
expected. This gives us the following code~:

\begin{lstlisting}
  symbol S : TYPE;
  symbol i1 : T → S;
  symbol i2 : U → S;
  symbol elim : (T → C) → (U → C) → S → C;
  rule elim $c1 _ (i1 $t) ↪ $c1 $t
  with elim _ $c2 (i2 $u) ↪ $c2 $u;
\end{lstlisting}

\subsubsection{Type codes}\label{codes}

The main limitation we have had is the absence of polymorphism, since we cannot
quantify over types. But we can quantify over types, so we can for example
create a type of codes of types, along with an interpretation function, and then
add codes for all the types that we want to represent. The basic framework would
be something like~:

\begin{lstlisting}
  symbol Set : TYPE;
  symbol El : Set → TYPE;
\end{lstlisting}

Now we can add a product type in $Set$~:

\begin{lstlisting}
  symbol P (A : Set) (B : A → Set) : Set;
  rule El (P $A $B) ↪ Π(x : El $A), $B x;
\end{lstlisting}

This way, $P$ is a code in $Set$ for the LambdaPi product type. But where this
approach really shines is that we can add codes for types that have no
equivalent in dedukti, and still use them naturally. For example, if we want to
add a polymorphic binary sum in $Set$, we can do it~:

\begin{lstlisting}
  symbol S : Set → Set → Set;
  symbol i1 (U V : Set) : El U → El (S U V);
  symbol i2 (U V : Set) : El V → El (S U V);
  symbol elim (U V C : Set) : (El U → El C)
                            → (El V → El C)
                            → El (S U V) → El C;
  rule elim _ _ _ $c1 _ (i1 _ _ $x) ↪ $c1 $x
  with elim _ _ _ _ $c2 (i2 _ _ $x) ↪ $c2 $x;
\end{lstlisting}

And now we have a sum type in $Set$ that is polymorphic over $Set$, but thanks
to the reduction rules it acts as a primitive sum type. And thus despite the
fact that there is no primitive sum type in LambdaPi. So this is the trick used
to have polymorphism in LambdaPi, and more generally to embed a logic that has
more primitive types than LambdaPi.

\subsection{Martin-Löf Type Theory}

Since LambdaPi is a logical framework, we first need to encode a specific logic
in it to work with. The logic we will work with is \emph{Martin-Löf Type Theory
with a hierarchy of non-cumulative universe}, which we will abbreviate
\emph{MLTT}. It is one of the most common basis for type systems with dependent
types. For example, the \emph{Calculus of Construction} is based on this
framework. The definition is pretty similar to the lambda-pi calculus, with
built-in polymorphism and more basic types, since there is no \emph{modulo} part
that can be used to add new parts. This type theory is often also called
\emph{Intentional Type Theory}, by opposition to \emph{Extensional Type Theory},
see section \ref{mltt-eq} for more details.

\subsubsection{Definition}

The syntax is that of the usual $\lambda$-calculus, with dependent sum, dependent
product, equality types, and a hierarchy of universe~:

\[\begin{array}{rcll}
    t, u, w, p, P, T, U, \dots & := & \lambda(x : T), t & \\
                               & |  & t\ u & \\
                               & |  & x & \\
                               & |  & \Pi(x : T), U & \\
                               & |  & \Sigma(x : T), U & \\
                               & |  & \pi_{1}(t) & \\
                               & |  & \pi_{2}(t) & \\
                               & |  & (t,u) & \\
                               & |  & t =_{T} u & \\
                               & |  & \text{refl}_{T}(t) & \\
                               & |  & J\ T\ t\ P\ w\ u\ p & \\
                               & |  & U_{s} & \text{for } s\in\mathbb{N} \\
\end{array}\]

Once again, the typing rules are pretty straightforward, and we will only
discuss those of particular interest. First let's see how to deal with
polymorphism by looking at the abstraction and product forming rules~:

\begin{center}\begin{prooftree}
  \hypo{\Gamma\vdash A : U_s}
  \hypo{\Gamma, x : A\vdash t : B}
  \infer2[Abs]{\Gamma\vdash \lambda(x : A), t : \Pi(x : A), B}
\end{prooftree}\quad\begin{prooftree}
  \hypo{\Gamma\vdash A : U_s}
  \hypo{\Gamma, x:A\vdash B : U_{s'}}
  \infer2[Prod]{\Gamma\vdash\Pi(x:A),B : U_{s\vee s'}}
\end{prooftree}\end{center}

So here we see that \emph{types} are elements of some $U_{s}$. So can we
quantify over types~? Well the answer is yes, due to the way universes are
typed~:

\begin{center}\begin{prooftree}
  \infer0{\Gamma\vdash U_s : U_{s+1}}
\end{prooftree}\end{center}

So while it is impossible to quantify over all types, it is possible to quantify
over all types of a certain level.

\subsubsection{Equality}\label{mltt-eq}

Equality deserves a specific discussion. Like with the lambda-pi calculus, there
is a notion of \emph{convertibility} $\Gamma\vdash t \equiv u$, which is used through the
conversion rule, and a notion of equality $\Gamma\vdash p : t =_{T} u$. In order to
distinguish the two, the former is called \emph{definitional equality} and the
latter \emph{propositional equality}.

Propositional equality is introduced through the following rule~:

\begin{center}\begin{prooftree}
  \hypo{\Gamma\vdash t : T}
  \infer1{\Gamma\vdash\text{refl}_T(t) : t =_T t}
\end{prooftree}\end{center}

Propositional equality can be seen as an internalisation of definitional
equality in the type theory. Indeed, if $\Gamma\vdash t \equiv u$, then, by congruence,
$\Gamma\vdash t =_{T} t \equiv t =_{T} u$, and thus, by conversion,
$\Gamma\vdash\text{refl}_{T}(t) : t =_{T} u$. But it can be manipulated as a proposition,
including abstracting over it, while this is impossible with definitional
equality.

Using propositional equality needs a specific term, and that is $J$~:

\begin{center}\begin{prooftree}
  \hypo{\Gamma\vdash t : T}
  \hypo{\Gamma, x : T, p : t =_T x\vdash P : U_s}
  \infer[no rule]2{\Gamma\vdash w : P[x\rightarrow t, p\rightarrow \text{refl}_T(t)]}
  \hypo{\Gamma\vdash u : T}
  \infer[no rule]1{\Gamma\vdash p : t =_T u}
  \infer2{\Gamma\vdash J\ T\ t\ P\ w\ u\ p : P[x\rightarrow u, p\rightarrow p]}
\end{prooftree}\end{center}

One way to look at it is that $J$ allows to treat the propositional equality as
an inductive type with only one constructor. This interpretation also allows us
to guess the computation rule for $J$~:

\begin{center}\begin{prooftree}
  \hypo{\Gamma\vdash t : T}
  \hypo{\Gamma, x : T, p : t =_T x\vdash P : U_s}
  \hypo{\Gamma\vdash w : P[x\rightarrow t, p\rightarrow \text{refl}_T(t)]}
  \infer3{\Gamma\vdash J\ T\ t\ P\ w\ t\ \text{refl}_T(t) \equiv w}
\end{prooftree}\end{center}

\subsubsection{Transport}\label{transport}

There is a specific usage of equality that will be very relevant for this
project. Recall that if we have $\Gamma\vdash t : T$ and $\Gamma\vdash T \equiv U$, then we have
$\Gamma\vdash t : U$ thanks to the conversion rule.  The question is, can we do something
similar with propositional equality~? Let's assume $\Gamma\vdash t : T$ and
$\Gamma\vdash p : T =_{U_{s}} U$. Can we have $\Gamma\vdash t : U$~? The answer is no, not in the
general case.  But we can create a term in $U$ from $t$ and $p$. That is, we
have~:

\[\Gamma\vdash J\ U_{s}\ T\ (\lambda(U : U_{s}), \lambda(p : T =_{U_{s}} U), U)\ t\ U\ p : U\]

Such a term is called the \emph{transport} of $t$ along $p$, and we will write
it $\text{transport}(p,t)$ from now on. Thanks to the computation rule for $J$,
we have that~:

\[\Gamma\vdash\text{transport}(\text{refl}_{U_{s}}(T),t) \equiv t\]

\subsubsection{Uniqueness of identity proofs}\label{uip}

In this section and the following one, we will describe common axioms that are
often used with MLTT.

Let's have another look at equality. Given $\Gamma\vdash t : T$ ans $\Gamma\vdash u : T$, there may
be multiple propositional equalities between $t$ and $u$. One may then wonder,
are they equal~? After all, when we eliminate them, we get the reflexivity. And
if they are, can there be multiple proof of equality between them~? More
generally, we can consider this whole tower of equalities, and equalities
between equalities, going on and on. Study of the structure and interaction
between all those equalities is what started the whole project of \emph{Homotopy
Type Theory}, which is well beyond this project. Another approach, that is still
consistent with MLTT, is to collapse everything by adding an axiom that says
that any two equalities are equal. This axiom is called \emph{Uniqueness of
identity proofs}, or \emph{UIP}~:

\begin{center}\begin{prooftree}
    \hypo{\Gamma\vdash t : T} \hypo{\Gamma\vdash u : T}
    \hypo{\Gamma\vdash p_1 : t =_T u} \hypo{\Gamma\vdash p_2 : t=_T u}
    \infer4{\Gamma\vdash \text{uip}(t,u,p_1,p_2) : p_1 =_{t=_T u} p_2}
\end{prooftree}\end{center}

This axiom is equivalent to another one, called the axiom $K$. It claims that
any equality is the reflexivity~:

\begin{center}\begin{prooftree}
    \hypo{\Gamma\vdash t : T} \hypo{\Gamma\vdash p : t =_T t}
    \infer2{\Gamma\vdash K(t,p) : p =_{t =_T t} \text{refl}_T(t)}
\end{prooftree}\end{center}

$K$ can be easily deducted from UIP, by applying the latter to $p$ and
$\text{refl}_{T}(t)$. For the other direction, one need to destruct $p_{1}$ and
then apply $K$ to $p_{2}$.

The main interest of using $K$ is that it can be given some computational
content, meaning one can define a computational rule for it~:

\begin{center}\begin{prooftree}
    \hypo{\Gamma\vdash t : T}
    \infer1{\Gamma\vdash K(t,\text{refl}_T(t)) \equiv \text{refl}_{t =_T t}(\text{refl}_T(t))}
\end{prooftree}\end{center}

\subsubsection{Functional extensionality}\label{funext}

Another axiom that is very useful is that of functional extensionality. It comes
from the fact that since functions have little structure to be exploited,
proving equality between functions beyond syntactic equality is often
impossible. Intuitively, two functions should be equal if they are pointwise
equal, as this is what set theory has gotten us used to. Well functional
extensionality is an axiom that says exactly that~:

\begin{center}\begin{prooftree}
    \hypo{\Gamma\vdash f : \Pi(x : A), B}
    \hypo{\Gamma\vdash g : \Pi(x : A), B}
    \hypo{\Gamma, x:A \vdash p : f\ x =_{B\ x} g\ x}
    \infer3{\Gamma\vdash f =_{\Pi(x : A), B} g}
\end{prooftree}\end{center}

\subsection{Embedding MLTT in $\lp$}
